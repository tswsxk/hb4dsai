# 知识蒸馏

## 综述

### 阅读材料

[「GitHub」知识蒸馏从入门到精通](https://mp.weixin.qq.com/s/EhoaYfIfK4KgfVsNjJFNAA)

[FAIR&MIT提出知识蒸馏新方法：数据集蒸馏](https://mp.weixin.qq.com/s/mFuxCl0Mzv5hmDFewWZkrw)

### 参考文献

【1】Hinton G, Vinyals O, Dean J. Distilling the knowledge in a neural network[J]. arXiv preprint arXiv:1503.02531, 2015.

```
@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}
```



##应用

### 自然语言处理

#### 阅读材料

[刷新CoQA榜单记录：基于对抗训练和知识蒸馏的机器阅读理解方案解析](https://mp.weixin.qq.com/s/H7tcMD927FoxTS4r-Igyow)

[BAM！利用知识蒸馏和多任务学习构建的通用语言模型 - 机器之心的文章 - 知乎](https://zhuanlan.zhihu.com/p/59613335)